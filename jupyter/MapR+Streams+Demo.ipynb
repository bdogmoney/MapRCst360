{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapR Streams\n",
    "\n",
    "MapR Streams brings integrated publish/subscribe messaging to the MapR Converged Data Platform. MapR Streams is ideal for a variety of use cases, including:\n",
    "\n",
    "- **Application event pipelines:** Many types of applications generate event or log data that needs to be centrally stored and analyzed to gain insights about user activity or application performance. MapR Streams simplifies these pipelines by transporting events to a central location where they can undergo event-by-event transformation and analysis.\n",
    "- **Database change capture:** Most modern databases allow users to generate an event each time an entry is added or modified. These events can be produced to MapR Streams to keep systems like search indices and caches synchronized, as well as feed security or notification applications.\n",
    "- **Internet of Things:** The explosion in the number of smart devices and sensors has created many situations in which billions of data points are created by millions of geographically dispersed sensors. MapR Streams provides a reliable, global transport for these messages, allowing analytics to be done both at the source and at a central location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Producer\n",
    "\n",
    "The following example code produces three messages to a topic named mytopic in a stream named my_stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mapr_streams_python import Producer\n",
    "p = Producer({'streams.producer.default.stream': '/user/mapr/mystream:mytopic'})\n",
    "some_data_source= [\"msg1\", \"msg2\", \"msg3\", '\\0']\n",
    "for data in some_data_source:\n",
    "    p.produce('/user/mapr/mystream:mytopic', data.encode('utf-8'))\n",
    "p.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Consumer\n",
    "\n",
    "In the following example, the MapR Streams consumer is subscribed to my_stream/mytopic and it prints the content of each message that it reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: msg1\n",
      "Received message: msg2\n",
      "Received message: msg3\n",
      "Received message: \u0000\n"
     ]
    }
   ],
   "source": [
    "# Consumer\n",
    "from mapr_streams_python import Consumer, KafkaError\n",
    "c = Consumer({'group.id': 'mygroup',\n",
    "              'default.topic.config': {'auto.offset.reset': 'earliest'}})\n",
    "c.subscribe(['/user/mapr/mystream:mytopic'])\n",
    "running = True\n",
    "while running:\n",
    "  msg = c.poll(timeout=1.0)\n",
    "  if msg is None: continue\n",
    "  if not msg.error():\n",
    "    msg_value = msg.value().decode('utf-8')\n",
    "    if msg_value  is '\\0':\n",
    "      running = False\n",
    "    print('Received message: %s' % msg_value)\n",
    "  elif msg.error().code() != KafkaError._PARTITION_EOF:\n",
    "    print(msg.error())\n",
    "    running = False\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
